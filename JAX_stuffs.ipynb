{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JAX_stuffs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM80i/JB9a0ENUC+BumdQzP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrumeterez/ai_notebooks/blob/master/JAX_stuffs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXal-4GJZWfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jax.numpy as np\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3C6xMBMMZb-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_params(in_size, out_size, key, scale=1e-2):\n",
        "    w_key, b_key = random.split(key)\n",
        "    w_params, b_params = scale * random.normal(w_key, (out_size, in_size)), \\\n",
        "                        scale * random.normal(b_key, (out_size, ))\n",
        "    return w_params, b_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo6rDz4gaAjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_network(sizes, key):\n",
        "    keys = random.split(key, len(sizes))\n",
        "    layers = []\n",
        "\n",
        "    for i in range(1, len(sizes)):\n",
        "        in_size = sizes[i-1]\n",
        "        out_size = sizes[i]\n",
        "        k = keys[i-1]\n",
        "\n",
        "        layers.append(random_params(in_size, out_size, k))\n",
        "    return layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Kmjv3tJbFx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layers = [784, 512, 512, 10]\n",
        "params = init_network(layers, random.PRNGKey(0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW591irGbND9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "423f32ce-e6cc-43b0-9d77-e71a0c9d1d0e"
      },
      "source": [
        "print([p[0].shape for p in params]) # weights\n",
        "print([p[1].shape for p in params]) # biases"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(512, 784), (512, 512), (10, 512)]\n",
            "[(512,), (512,), (10,)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah-CliUibOT4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "def cross_entropy(x, y):\n",
        "    return -np.mean(x * np.log(y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzZJxa9Od8X8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(params, image):\n",
        "    activations = image\n",
        "    for w, b in params[:-1]:\n",
        "        activations = relu(np.dot(w, activations) + b)\n",
        "    last_w, last_b = params[-1]\n",
        "    logits = np.dot(last_w, activations) + last_b\n",
        "\n",
        "    return softmax(logits)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w1_kEU6eE9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab76fef4-a375-4461-8d7c-48d42cd3014e"
      },
      "source": [
        "random_image = random.normal(random.PRNGKey(1), (28*28, ))\n",
        "logits = predict(params, random_image)\n",
        "print(logits.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpY-W6bXeaVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fucks up with bathces, use vmap\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pzg7ZjIem9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4c336587-411b-4333-b153-78572e5f40d3"
      },
      "source": [
        "random_image_batch = random.normal(random.PRNGKey(1), (1, 28*28))\n",
        "print(random_image_batch.shape)\n",
        "logits = batched_predict(params, random_image_batch)\n",
        "print(logits.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 784)\n",
            "(1, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "au0H_atVfnuv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15eb1e0f-09d3-4e3a-be5a-5d8aa84461d6"
      },
      "source": [
        "print(logits[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.10200009 0.10042951 0.1009826  0.09725185 0.09946808 0.09856772\n",
            " 0.09960646 0.10060352 0.10020161 0.10088862]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7SfXGbBf4kB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(params, images, targets):\n",
        "    predictions = batched_predict(params, images)\n",
        "    loss = cross_entropy(targets, predictions)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOaT6a8sgiHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4700a72c-63a5-4fb9-8d8b-065ac4153c3a"
      },
      "source": [
        "loss(params, random_image_batch, np.array([0,1,2,3,4,5,6,7,8,9]))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(10.365537, dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkCwa_66grB3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@jit\n",
        "def update(params, x, y):\n",
        "    grads = grad(loss)(params, x, y)\n",
        "    updated_params = []\n",
        "    for (w, b), (dw, db) in zip(params, grads):\n",
        "        updated_params.append((w - 0.01 * dw, b - 0.01 * db))\n",
        "    return updated_params"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUA2C5RshOzL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(x, k, dtype=np.float32):\n",
        "  \"\"\"Create a one-hot encoding of x of size k.\"\"\"\n",
        "  return np.array(x[:, None] == np.arange(k), dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQH31AFuhe-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 256\n",
        "import numpy as onp\n",
        "from torch.utils import data\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "def numpy_collate(batch):\n",
        "  if isinstance(batch[0], onp.ndarray):\n",
        "    return onp.stack(batch)\n",
        "  elif isinstance(batch[0], (tuple,list)):\n",
        "    transposed = zip(*batch)\n",
        "    return [numpy_collate(samples) for samples in transposed]\n",
        "  else:\n",
        "    return onp.array(batch)\n",
        "\n",
        "class NumpyLoader(data.DataLoader):\n",
        "  def __init__(self, dataset, batch_size=1,\n",
        "                shuffle=False, sampler=None,\n",
        "                batch_sampler=None, num_workers=0,\n",
        "                pin_memory=False, drop_last=False,\n",
        "                timeout=0, worker_init_fn=None):\n",
        "    super(self.__class__, self).__init__(dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        sampler=sampler,\n",
        "        batch_sampler=batch_sampler,\n",
        "        num_workers=num_workers,\n",
        "        collate_fn=numpy_collate,\n",
        "        pin_memory=pin_memory,\n",
        "        drop_last=drop_last,\n",
        "        timeout=timeout,\n",
        "        worker_init_fn=worker_init_fn)\n",
        "\n",
        "class FlattenAndCast(object):\n",
        "  def __call__(self, pic):\n",
        "    return onp.ravel(onp.array(pic, dtype=np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t77cHVnLhhcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define our dataset, using torch datasets\n",
        "mnist_dataset = MNIST('/tmp/mnist/', download=True, transform=FlattenAndCast())\n",
        "training_generator = NumpyLoader(mnist_dataset, batch_size=batch_size, num_workers=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7B_2oVwhjvz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "e137c52b-7fcd-44a0-bc30-ead0c233a77d"
      },
      "source": [
        "n_targets = 10\n",
        "# Get the full train dataset (for checking accuracy while training)\n",
        "train_images = onp.array(mnist_dataset.train_data).reshape(len(mnist_dataset.train_data), -1)\n",
        "train_labels = one_hot(onp.array(mnist_dataset.train_labels), n_targets)\n",
        "\n",
        "# Get full test dataset\n",
        "mnist_dataset_test = MNIST('/tmp/mnist/', download=True, train=False)\n",
        "test_images = np.array(mnist_dataset_test.test_data.numpy().reshape(len(mnist_dataset_test.test_data), -1), dtype=np.float32)\n",
        "test_labels = one_hot(onp.array(mnist_dataset_test.test_labels), n_targets)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:55: UserWarning: train_data has been renamed data\n",
            "  warnings.warn(\"train_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:45: UserWarning: train_labels has been renamed targets\n",
            "  warnings.warn(\"train_labels has been renamed targets\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6i8kgv4hr0i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "3cf960cb-992e-4d97-ec19-a136f3e2cbd9"
      },
      "source": [
        "for epoch in range(20):\n",
        "    epoch_loss = 0.0\n",
        "    n_batches = len(training_generator)\n",
        "    for i, (x, y) in enumerate(training_generator):\n",
        "        # print(f\"Batch {i+1}/{n_batches}\")\n",
        "        y = one_hot(y, n_targets)\n",
        "        params = update(params, x, y)\n",
        "        epoch_loss += loss(params, x, y)\n",
        "    print(f\"Epoch: {epoch+1}\\n\\tLoss: {epoch_loss / n_batches}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "\tLoss: 0.05866694822907448\n",
            "Epoch: 2\n",
            "\tLoss: 0.027958426624536514\n",
            "Epoch: 3\n",
            "\tLoss: 0.02301833964884281\n",
            "Epoch: 4\n",
            "\tLoss: 0.020027145743370056\n",
            "Epoch: 5\n",
            "\tLoss: 0.017832688987255096\n",
            "Epoch: 6\n",
            "\tLoss: 0.016106652095913887\n",
            "Epoch: 7\n",
            "\tLoss: 0.014697279781103134\n",
            "Epoch: 8\n",
            "\tLoss: 0.01351588498800993\n",
            "Epoch: 9\n",
            "\tLoss: 0.012503830716013908\n",
            "Epoch: 10\n",
            "\tLoss: 0.011626585386693478\n",
            "Epoch: 11\n",
            "\tLoss: 0.010854005813598633\n",
            "Epoch: 12\n",
            "\tLoss: 0.010166967287659645\n",
            "Epoch: 13\n",
            "\tLoss: 0.009551472961902618\n",
            "Epoch: 14\n",
            "\tLoss: 0.008995779789984226\n",
            "Epoch: 15\n",
            "\tLoss: 0.008492236956954002\n",
            "Epoch: 16\n",
            "\tLoss: 0.008033220656216145\n",
            "Epoch: 17\n",
            "\tLoss: 0.007611940614879131\n",
            "Epoch: 18\n",
            "\tLoss: 0.0072233108803629875\n",
            "Epoch: 19\n",
            "\tLoss: 0.006865765433758497\n",
            "Epoch: 20\n",
            "\tLoss: 0.006535021588206291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGD6nt9Nh1XA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}